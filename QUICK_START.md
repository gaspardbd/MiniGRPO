# ğŸš€ Guide de DÃ©marrage Rapide - Google Colab

## âœ… Modifications effectuÃ©es

Le problÃ¨me a Ã©tÃ© identifiÃ© et corrigÃ© :
- âŒ **Avant** : `LiquidAI/LFM2-350M` ne gÃ©nÃ©rait pas les balises `<answer>` â†’ rewards Ã  0
- âœ… **Maintenant** : `Qwen/Qwen2.5-0.5B-Instruct` suit correctement le format

## ğŸ“‹ Instructions pour relancer dans Colab

### 1. **Stoppez l'entraÃ®nement actuel**
Dans votre notebook Colab, cliquez sur le bouton STOP (â¹ï¸) ou utilisez Runtime â†’ Interrupt execution

### 2. **Mettez Ã  jour le code**
ExÃ©cutez cette cellule dans Colab :

```python
%cd /content/MiniGRPO
!git pull origin main
```

### 3. **[OPTIONNEL] Testez le nouveau modÃ¨le d'abord**
Pour vÃ©rifier que Qwen gÃ©nÃ¨re bien les balises `<answer>` :

```python
%cd /content/MiniGRPO
!python test_generation.py
```

Vous devriez voir des sorties comme :
```
âœ… Found <answer> tag!
   Predicted: '5'
   Expected: '5'
   Match: True
```

### 4. **Relancez l'entraÃ®nement**
Choisissez une des deux mÃ©thodes :

**Option A : Python (RecommandÃ©)**
```python
import os
os.environ['PYTHONUNBUFFERED'] = '1'
os.chdir('/content/MiniGRPO')
%run train.py
```

**Option B : Bash**
```bash
%%bash
cd /content/MiniGRPO
export PYTHONUNBUFFERED=1
python -u train.py 2>&1 | tee train.log
```

## ğŸ“Š Ce que vous devriez voir maintenant

### âœ… Configuration au dÃ©marrage
```
============================================================
TRAINING CONFIGURATION
============================================================
Model: Qwen/Qwen2.5-0.5B-Instruct
Loaded 100000 prompts
Batch size: 4
Rollouts per sample: 4
Total possible steps: 25000
Steps to run (max_steps): 100
Checkpoint interval: every 20 steps
============================================================
```

### âœ… Pendant l'entraÃ®nement
```
============================================================
Step 1/100 (0.0%): starting rollouts
============================================================
  Sample 1/4: generating 4 rollouts...
  
  ğŸ” DEBUG - First completion sample:
  Question: What is 2 + 3?...
  Expected answer: 5
  Generated completion: <think>To add 2 and 3...</think><answer>5</answer>
  ---
  
  Sample 1: generation done. Rewards: [1.0, 1.0, 0.5, 1.0]  â† Rewards > 0 !

ğŸ“Š Rollout Summary:
  Buffer size: 16
  Mean reward: 0.8750  â† Bon signe !
  Min/Max reward: 0.50/1.00

ğŸ”„ Training phase starting...
  Epoch 1/1, Batch 1: loss=0.3456  â† Loss normale (< 10)
```

## ğŸ¯ Signes de succÃ¨s

âœ… **Rewards > 0** (idÃ©alement 0.3-0.8 au dÃ©but)
âœ… **Loss < 10** (typiquement 0.1-5.0)
âœ… **Vitesse** : ~2-5 minutes par step (beaucoup plus rapide qu'avant)
âœ… **Debug message** montre des balises `<answer>` dans les gÃ©nÃ©rations

## âš™ï¸ ParamÃ¨tres actuels

- **max_steps = 100** : L'entraÃ®nement s'arrÃªtera aprÃ¨s 100 steps (~3-8 heures)
- Pour un entraÃ®nement complet, modifiez dans `train.py` ligne 158 :
  ```python
  max_steps = 5000  # ou None pour aller jusqu'au bout
  ```

## ğŸ› Si Ã§a ne marche toujours pas

### ProblÃ¨me : Rewards toujours Ã  0
**Solution** : VÃ©rifiez le message DEBUG. Si pas de balise `<answer>`, le modÃ¨le n'est pas chargÃ© correctement.

### ProblÃ¨me : Loss explosive (> 100)
**Solution** : 
1. RÃ©duisez le learning rate dans `train.py` ligne 173 :
   ```python
   optimizer=torch.optim.AdamW(model.parameters(), lr=5e-5)  # au lieu de 1e-4
   ```

### ProblÃ¨me : Out of memory
**Solution** :
1. RÃ©duisez `batch_size` de 4 Ã  2 (ligne 148)
2. RÃ©duisez `num_rollout` de 4 Ã  2 (ligne 154)
3. RÃ©duisez `max_length` de 512 Ã  256 (ligne 149)

## ğŸ“ˆ Progression attendue

Avec Qwen2.5-0.5B-Instruct, vous devriez voir :
- **Steps 1-10** : Mean reward ~0.2-0.4, loss ~2-5
- **Steps 10-30** : Mean reward ~0.4-0.6, loss ~1-3
- **Steps 30-100** : Mean reward ~0.6-0.8, loss ~0.5-2

Le modÃ¨le apprend Ã  mieux formater ses rÃ©ponses et Ã  rÃ©soudre les problÃ¨mes mathÃ©matiques !

## ğŸ’¾ Checkpoints

Les modÃ¨les sont sauvegardÃ©s dans `/content/MiniGRPO/output/` tous les 20 steps :
- `output/step_20/`
- `output/step_40/`
- `output/step_60/`
- etc.

Pour tÃ©lÃ©charger un checkpoint depuis Colab :
```python
!zip -r checkpoint_step_40.zip output/step_40/
from google.colab import files
files.download('checkpoint_step_40.zip')
```

Bon entraÃ®nement ! ğŸ‰

